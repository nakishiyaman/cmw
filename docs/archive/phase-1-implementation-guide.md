# Phase 1 å®Ÿè£…ã‚¬ã‚¤ãƒ‰ - ã‚¿ã‚¹ã‚¯ç®¡ç†å±¤

**ç›®çš„**: cmwã‚’Claude Codeã¨çµ±åˆã™ã‚‹ãŸã‚ã®åŸºç›¤ã‚’æ§‹ç¯‰  
**æ¨å®šæ™‚é–“**: 3-4æ™‚é–“  
**å‰æ**: Phase 0ï¼ˆåŸºç›¤æ§‹ç¯‰ï¼‰ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨

---

## ğŸ¯ Phase 1ã®ç›®æ¨™

Claude CodeãŒä»¥ä¸‹ã®ã“ã¨ã‚’ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹:

```python
# 1. æ¬¡ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
task = cmw.get_next_task()

# 2. ã‚¿ã‚¹ã‚¯ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
context = cmw.get_task_context(task.id)

# 3. Claude CodeãŒã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆè‡ªèº«ã®èƒ½åŠ›ï¼‰

# 4. å®Œäº†å ±å‘Š
cmw.mark_completed(task.id, ["backend/auth.py"])
```

---

## ğŸ“‹ å®Ÿè£…ã™ã‚‹3ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

### 1. TaskProviderï¼ˆ2æ™‚é–“ï¼‰â­ æœ€å„ªå…ˆ
- ã‚¿ã‚¹ã‚¯æƒ…å ±ã®æä¾›
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
- çŠ¶æ…‹æ›´æ–°

### 2. StateManagerï¼ˆ1æ™‚é–“ï¼‰
- æ°¸ç¶šåŒ–
- ãƒ­ãƒƒã‚¯æ©Ÿæ§‹
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†

### 3. ParallelExecutorï¼ˆ1-2æ™‚é–“ï¼‰
- ä¸¦åˆ—å®Ÿè¡Œåˆ¤å®š
- ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆæ¤œå‡º

---

## ğŸ”¨ Phase 1.1: TaskProviderå®Ÿè£…

### ãƒ•ã‚¡ã‚¤ãƒ«: `src/cmw/task_provider.py`

```python
"""
TaskProvider - Claude Codeã«ã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’æä¾›

å½¹å‰²:
- æ¬¡ã«å®Ÿè¡Œã™ã¹ãã‚¿ã‚¹ã‚¯ã‚’é¸æŠ
- ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã«å¿…è¦ãªå…¨æƒ…å ±ã‚’æä¾›
- ã‚¿ã‚¹ã‚¯å®Œäº†/å¤±æ•—ã®è¨˜éŒ²
"""
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime
import json

from .models import Task, TaskStatus
from .coordinator import Coordinator


class TaskProvider:
    """Claude Codeã¸ã®ã‚¿ã‚¹ã‚¯æƒ…å ±æä¾›"""
    
    def __init__(self, project_path: Path):
        """
        Args:
            project_path: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
        """
        self.project_path = Path(project_path)
        self.coordinator = Coordinator(project_path)
        self.progress_file = project_path / "shared/coordination/progress.json"
        
        # é€²æ—æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
        self._load_progress()
    
    def get_next_task(self) -> Optional[Task]:
        """
        æ¬¡ã«å®Ÿè¡Œã™ã¹ãã‚¿ã‚¹ã‚¯ã‚’å–å¾—
        
        ä¾å­˜é–¢ä¿‚ã‚’è€ƒæ…®ã—ã€å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ä¸­ã‹ã‚‰
        å„ªå…ˆåº¦ã®é«˜ã„ã‚‚ã®ã‚’è¿”ã™
        
        Returns:
            å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã€ãªã‘ã‚Œã°None
        """
        # å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã‚’å–å¾—ï¼ˆä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ï¼‰
        ready_tasks = self._get_ready_tasks()
        
        if not ready_tasks:
            return None
        
        # å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        ready_tasks.sort(key=lambda t: (
            t.priority == "high",    # é«˜å„ªå…ˆåº¦ã‚’å…ˆã«
            t.priority == "medium",
            -len(t.dependencies)     # ä¾å­˜ãŒå°‘ãªã„ã‚‚ã®ã‚’å…ˆã«
        ), reverse=True)
        
        return ready_tasks[0]
    
    def get_task_context(self, task_id: str) -> Dict:
        """
        ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã«å¿…è¦ãªå…¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        
        Args:
            task_id: ã‚¿ã‚¹ã‚¯ID
            
        Returns:
            ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã«å¿…è¦ãªæƒ…å ±ã‚’å«ã‚€è¾æ›¸
        """
        task = self.coordinator.get_task(task_id)
        if not task:
            raise ValueError(f"Task {task_id} not found")
        
        return {
            "task": {
                "id": task.id,
                "title": task.title,
                "description": task.description,
                "target_files": task.target_files,
                "acceptance_criteria": task.acceptance_criteria
            },
            "requirements": self._load_requirements_section(task),
            "api_spec": self._load_api_spec(task),
            "related_files": self._get_related_files(task),
            "dependencies_artifacts": self._get_dependency_artifacts(task),
            "project_structure": self._get_project_structure()
        }
    
    def mark_started(self, task_id: str):
        """
        ã‚¿ã‚¹ã‚¯é–‹å§‹ã‚’è¨˜éŒ²
        
        Args:
            task_id: ã‚¿ã‚¹ã‚¯ID
        """
        task = self.coordinator.get_task(task_id)
        if not task:
            raise ValueError(f"Task {task_id} not found")
        
        task.status = TaskStatus.IN_PROGRESS
        task.started_at = datetime.now().isoformat()
        
        self._save_progress()
    
    def mark_completed(self, task_id: str, artifacts: List[str]):
        """
        ã‚¿ã‚¹ã‚¯å®Œäº†ã‚’è¨˜éŒ²
        
        Args:
            task_id: ã‚¿ã‚¹ã‚¯ID
            artifacts: ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
        """
        task = self.coordinator.get_task(task_id)
        if not task:
            raise ValueError(f"Task {task_id} not found")
        
        task.status = TaskStatus.COMPLETED
        task.completed_at = datetime.now().isoformat()
        task.artifacts = artifacts
        
        self._save_progress()
        
        # ä¾å­˜ã‚¿ã‚¹ã‚¯ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’è§£é™¤
        self._unblock_dependent_tasks(task_id)
    
    def mark_failed(self, task_id: str, error: str):
        """
        ã‚¿ã‚¹ã‚¯å¤±æ•—ã‚’è¨˜éŒ²
        
        Args:
            task_id: ã‚¿ã‚¹ã‚¯ID
            error: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        task = self.coordinator.get_task(task_id)
        if not task:
            raise ValueError(f"Task {task_id} not found")
        
        task.status = TaskStatus.FAILED
        task.error = error
        task.failed_at = datetime.now().isoformat()
        
        self._save_progress()
        
        # ä¾å­˜ã‚¿ã‚¹ã‚¯ã‚’ãƒ–ãƒ­ãƒƒã‚¯çŠ¶æ…‹ã«
        self._block_dependent_tasks(task_id)
    
    # === ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def _get_ready_tasks(self) -> List[Task]:
        """ä¾å­˜é–¢ä¿‚ã‚’æº€ãŸã—ãŸå®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
        ready = []
        
        for task in self.coordinator.tasks.values():
            # æ—¢ã«å®Œäº†æ¸ˆã¿ã¯ã‚¹ã‚­ãƒƒãƒ—
            if task.status == TaskStatus.COMPLETED:
                continue
            
            # ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—
            if task.status == TaskStatus.BLOCKED:
                continue
            
            # ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯
            if self._are_dependencies_met(task):
                ready.append(task)
        
        return ready
    
    def _are_dependencies_met(self, task: Task) -> bool:
        """ã‚¿ã‚¹ã‚¯ã®ä¾å­˜é–¢ä¿‚ãŒæº€ãŸã•ã‚Œã¦ã„ã‚‹ã‹"""
        for dep_id in task.dependencies:
            dep_task = self.coordinator.get_task(dep_id)
            if not dep_task or dep_task.status != TaskStatus.COMPLETED:
                return False
        return True
    
    def _load_requirements_section(self, task: Task) -> str:
        """requirements.mdã‹ã‚‰é–¢é€£ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’èª­ã¿è¾¼ã¿"""
        req_file = self.project_path / "shared/docs/requirements.md"
        if not req_file.exists():
            return ""
        
        content = req_file.read_text(encoding='utf-8')
        
        # ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º
        # ï¼ˆç°¡æ˜“å®Ÿè£…: å°†æ¥çš„ã«ã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ï¼‰
        return content
    
    def _load_api_spec(self, task: Task) -> str:
        """APIä»•æ§˜ã‹ã‚‰é–¢é€£éƒ¨åˆ†ã‚’èª­ã¿è¾¼ã¿"""
        api_file = self.project_path / "shared/docs/api-spec.md"
        if not api_file.exists():
            return ""
        
        return api_file.read_text(encoding='utf-8')
    
    def _get_related_files(self, task: Task) -> List[str]:
        """ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        related = []
        artifacts_dir = self.project_path / "shared/artifacts"
        
        # target_filesã«é–¢é€£ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        for target in task.target_files:
            target_path = artifacts_dir / target
            if target_path.exists():
                related.append({
                    "path": target,
                    "content": target_path.read_text(encoding='utf-8')
                })
        
        return related
    
    def _get_dependency_artifacts(self, task: Task) -> List[Dict]:
        """ä¾å­˜ã‚¿ã‚¹ã‚¯ã®æˆæœç‰©ã‚’å–å¾—"""
        artifacts = []
        
        for dep_id in task.dependencies:
            dep_task = self.coordinator.get_task(dep_id)
            if dep_task and dep_task.status == TaskStatus.COMPLETED:
                for artifact_path in dep_task.artifacts:
                    full_path = self.project_path / "shared/artifacts" / artifact_path
                    if full_path.exists():
                        artifacts.append({
                            "task_id": dep_id,
                            "path": artifact_path,
                            "content": full_path.read_text(encoding='utf-8')
                        })
        
        return artifacts
    
    def _get_project_structure(self) -> Dict:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®æƒ…å ±ã‚’å–å¾—"""
        return {
            "backend_dir": "shared/artifacts/backend",
            "frontend_dir": "shared/artifacts/frontend",
            "tests_dir": "shared/artifacts/tests"
        }
    
    def _unblock_dependent_tasks(self, completed_task_id: str):
        """ä¾å­˜ã‚¿ã‚¹ã‚¯ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’è§£é™¤"""
        for task in self.coordinator.tasks.values():
            if completed_task_id in task.dependencies:
                if self._are_dependencies_met(task):
                    if task.status == TaskStatus.BLOCKED:
                        task.status = TaskStatus.PENDING
    
    def _block_dependent_tasks(self, failed_task_id: str):
        """ä¾å­˜ã‚¿ã‚¹ã‚¯ã‚’ãƒ–ãƒ­ãƒƒã‚¯çŠ¶æ…‹ã«"""
        for task in self.coordinator.tasks.values():
            if failed_task_id in task.dependencies:
                task.status = TaskStatus.BLOCKED
    
    def _load_progress(self):
        """é€²æ—æƒ…å ±ã‚’èª­ã¿è¾¼ã¿"""
        if not self.progress_file.exists():
            self._init_progress()
            return
        
        progress = json.loads(self.progress_file.read_text(encoding='utf-8'))
        
        # ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ã‚’å¾©å…ƒ
        for task_id, task_data in progress.get("tasks", {}).items():
            task = self.coordinator.get_task(task_id)
            if task:
                task.status = TaskStatus(task_data.get("status", "pending"))
                task.started_at = task_data.get("started_at")
                task.completed_at = task_data.get("completed_at")
                task.artifacts = task_data.get("artifacts", [])
                task.error = task_data.get("error")
    
    def _save_progress(self):
        """é€²æ—æƒ…å ±ã‚’ä¿å­˜"""
        progress = {
            "updated_at": datetime.now().isoformat(),
            "tasks": {}
        }
        
        for task_id, task in self.coordinator.tasks.items():
            progress["tasks"][task_id] = {
                "id": task.id,
                "status": task.status.value,
                "started_at": task.started_at,
                "completed_at": task.completed_at,
                "artifacts": task.artifacts,
                "error": task.error
            }
        
        self.progress_file.parent.mkdir(parents=True, exist_ok=True)
        self.progress_file.write_text(
            json.dumps(progress, indent=2, ensure_ascii=False),
            encoding='utf-8'
        )
    
    def _init_progress(self):
        """é€²æ—æƒ…å ±ã‚’åˆæœŸåŒ–"""
        progress = {
            "created_at": datetime.now().isoformat(),
            "tasks": {}
        }
        
        for task_id, task in self.coordinator.tasks.items():
            progress["tasks"][task_id] = {
                "id": task.id,
                "status": TaskStatus.PENDING.value,
                "started_at": None,
                "completed_at": None,
                "artifacts": [],
                "error": None
            }
        
        self.progress_file.parent.mkdir(parents=True, exist_ok=True)
        self.progress_file.write_text(
            json.dumps(progress, indent=2, ensure_ascii=False),
            encoding='utf-8'
        )
```

---

## ğŸ”¨ Phase 1.2: StateManagerå®Ÿè£…

### ãƒ•ã‚¡ã‚¤ãƒ«: `src/cmw/state_manager.py`

```python
"""
StateManager - çŠ¶æ…‹ã®æ°¸ç¶šåŒ–ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†

å½¹å‰²:
- è¤‡æ•°ã‚»ãƒƒã‚·ãƒ§ãƒ³é–“ã§ã®çŠ¶æ…‹å…±æœ‰
- ãƒ­ãƒƒã‚¯æ©Ÿæ§‹ã«ã‚ˆã‚‹ç«¶åˆå›é¿
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç¶™ç¶šæ€§ä¿è¨¼
"""
from pathlib import Path
from typing import Optional
import json
import time
import os


class StateManager:
    """çŠ¶æ…‹ç®¡ç†ã¨ãƒ­ãƒƒã‚¯æ©Ÿæ§‹"""
    
    LOCK_TIMEOUT = 300  # 5åˆ†
    
    def __init__(self, project_path: Path):
        self.project_path = Path(project_path)
        self.progress_file = project_path / "shared/coordination/progress.json"
        self.lock_file = project_path / "shared/coordination/.lock"
    
    def acquire_lock(self, timeout: int = 10) -> bool:
        """
        ãƒ­ãƒƒã‚¯ã‚’å–å¾—
        
        Args:
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°
            
        Returns:
            ãƒ­ãƒƒã‚¯å–å¾—æˆåŠŸãªã‚‰True
        """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if self._try_acquire_lock():
                return True
            time.sleep(0.1)
        
        return False
    
    def release_lock(self):
        """ãƒ­ãƒƒã‚¯ã‚’è§£æ”¾"""
        if self.lock_file.exists():
            try:
                self.lock_file.unlink()
            except FileNotFoundError:
                pass  # æ—¢ã«å‰Šé™¤æ¸ˆã¿
    
    def is_locked(self) -> bool:
        """ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
        if not self.lock_file.exists():
            return False
        
        lock_data = self._read_lock()
        if not lock_data:
            return False
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
        if time.time() - lock_data['timestamp'] > self.LOCK_TIMEOUT:
            # å¤ã„ãƒ­ãƒƒã‚¯ã¯ç„¡åŠ¹
            self.release_lock()
            return False
        
        return True
    
    def get_lock_info(self) -> Optional[dict]:
        """ãƒ­ãƒƒã‚¯æƒ…å ±ã‚’å–å¾—"""
        if not self.lock_file.exists():
            return None
        
        return self._read_lock()
    
    def _try_acquire_lock(self) -> bool:
        """ãƒ­ãƒƒã‚¯å–å¾—ã‚’è©¦ã¿ã‚‹"""
        # æ—¢ã«ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if self.is_locked():
            return False
        
        # ãƒ­ãƒƒã‚¯ã‚’ä½œæˆ
        lock_data = {
            'session_id': os.getpid(),
            'timestamp': time.time(),
            'hostname': os.uname().nodename if hasattr(os, 'uname') else 'unknown'
        }
        
        self.lock_file.parent.mkdir(parents=True, exist_ok=True)
        self.lock_file.write_text(
            json.dumps(lock_data, indent=2),
            encoding='utf-8'
        )
        
        return True
    
    def _read_lock(self) -> Optional[dict]:
        """ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            return json.loads(self.lock_file.read_text(encoding='utf-8'))
        except (FileNotFoundError, json.JSONDecodeError):
            return None


class SessionContext:
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    
    ä½¿ç”¨ä¾‹:
        with SessionContext(project_path) as session:
            # ãƒ­ãƒƒã‚¯ã‚’å–å¾—ã—ãŸçŠ¶æ…‹ã§ä½œæ¥­
            provider = TaskProvider(project_path)
            task = provider.get_next_task()
        # ãƒ­ãƒƒã‚¯è‡ªå‹•è§£æ”¾
    """
    
    def __init__(self, project_path: Path):
        self.state_manager = StateManager(project_path)
    
    def __enter__(self):
        if not self.state_manager.acquire_lock():
            raise RuntimeError(
                "Could not acquire lock. "
                "Another session may be running."
            )
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.state_manager.release_lock()
```

---

## ğŸ”¨ Phase 1.3: ParallelExecutorå®Ÿè£…

### ãƒ•ã‚¡ã‚¤ãƒ«: `src/cmw/parallel_executor.py`

```python
"""
ParallelExecutor - ä¸¦åˆ—å®Ÿè¡Œã®åˆ¶å¾¡

å½¹å‰²:
- ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆã®æ¤œå‡º
- ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®åˆ¤å®š
- å®Ÿè¡Œã‚°ãƒ«ãƒ¼ãƒ—ã®ç®¡ç†
"""
from pathlib import Path
from typing import List, Set
from .models import Task
from .task_provider import TaskProvider


class ParallelExecutor:
    """ä¸¦åˆ—å®Ÿè¡Œã®åˆ¶å¾¡"""
    
    def __init__(self, project_path: Path):
        self.project_path = Path(project_path)
        self.provider = TaskProvider(project_path)
    
    def get_executable_tasks(self, max_parallel: int = 3) -> List[Task]:
        """
        ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã‚’å–å¾—
        
        Args:
            max_parallel: æœ€å¤§ä¸¦åˆ—å®Ÿè¡Œæ•°
            
        Returns:
            ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆ
        """
        # æº–å‚™å®Œäº†ã‚¿ã‚¹ã‚¯ã‚’å…¨ã¦å–å¾—
        ready_tasks = self._get_all_ready_tasks()
        
        if not ready_tasks:
            return []
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆã‚’è€ƒæ…®ã—ã¦é¸æŠ
        executable = []
        used_files: Set[str] = set()
        
        for task in ready_tasks:
            if len(executable) >= max_parallel:
                break
            
            task_files = self._get_task_files(task)
            
            # æ—¢ã«ä½¿ç”¨ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨é‡è¤‡ã—ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            if not task_files & used_files:
                executable.append(task)
                used_files.update(task_files)
        
        return executable
    
    def can_run_parallel(self, task1: Task, task2: Task) -> bool:
        """
        2ã¤ã®ã‚¿ã‚¹ã‚¯ãŒä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ã‹åˆ¤å®š
        
        Args:
            task1, task2: ã‚¿ã‚¹ã‚¯
            
        Returns:
            ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚‰True
        """
        files1 = self._get_task_files(task1)
        files2 = self._get_task_files(task2)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒé‡è¤‡ã—ã¦ã„ãªã‘ã‚Œã°ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½
        return not (files1 & files2)
    
    def group_tasks_by_parallelism(self, tasks: List[Task]) -> List[List[Task]]:
        """
        ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã‚‹
        
        Args:
            tasks: ã‚¿ã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒªã‚¹ãƒˆ
        """
        groups = []
        remaining = tasks.copy()
        
        while remaining:
            # æ–°ã—ã„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
            group = []
            used_files: Set[str] = set()
            
            # ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã«è¿½åŠ 
            for task in remaining[:]:
                task_files = self._get_task_files(task)
                
                if not task_files & used_files:
                    group.append(task)
                    used_files.update(task_files)
                    remaining.remove(task)
            
            if group:
                groups.append(group)
            else:
                # ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢
                break
        
        return groups
    
    # === ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def _get_all_ready_tasks(self) -> List[Task]:
        """å®Ÿè¡Œå¯èƒ½ãªå…¨ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
        ready = []
        task = self.provider.get_next_task()
        
        # æ¬¡ã®ã‚¿ã‚¹ã‚¯ã‚’é †æ¬¡å–å¾—
        while task:
            ready.append(task)
            # ä¸€æ™‚çš„ã«å®Ÿè¡Œä¸­ã«ãƒãƒ¼ã‚¯ï¼ˆç«¶åˆãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
            task.status = TaskStatus.IN_PROGRESS
            task = self.provider.get_next_task()
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æˆ»ã™
        for t in ready:
            t.status = TaskStatus.PENDING
        
        return ready
    
    def _get_task_files(self, task: Task) -> Set[str]:
        """
        ã‚¿ã‚¹ã‚¯ãŒæ‰±ã†ãƒ•ã‚¡ã‚¤ãƒ«ã®é›†åˆã‚’å–å¾—
        
        target_files ã¨ related_files ã®ä¸¡æ–¹ã‚’å«ã‚€
        """
        files = set(task.target_files)
        
        # ä¾å­˜ã‚¿ã‚¹ã‚¯ã®æˆæœç‰©ã‚‚å«ã‚ã‚‹ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ã ãŒå¿µã®ãŸã‚ï¼‰
        for dep_id in task.dependencies:
            dep_task = self.provider.coordinator.get_task(dep_id)
            if dep_task and dep_task.artifacts:
                files.update(dep_task.artifacts)
        
        return files
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

### ãƒ•ã‚¡ã‚¤ãƒ«: `tests/test_task_provider.py`

```python
"""
TaskProviderã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
"""
import pytest
from pathlib import Path
import tempfile
import shutil
from cmw.task_provider import TaskProvider
from cmw.models import Task, TaskStatus


@pytest.fixture
def test_project():
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ"""
    temp_dir = Path(tempfile.mkdtemp())
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆ
    (temp_dir / "shared/coordination").mkdir(parents=True)
    (temp_dir / "shared/docs").mkdir(parents=True)
    (temp_dir / "shared/artifacts").mkdir(parents=True)
    
    # tasks.jsonã‚’ä½œæˆ
    tasks = {
        "tasks": [
            {
                "id": "TASK-001",
                "title": "ã‚¿ã‚¹ã‚¯1",
                "description": "èª¬æ˜1",
                "dependencies": [],
                "target_files": ["file1.py"],
                "priority": "high"
            },
            {
                "id": "TASK-002",
                "title": "ã‚¿ã‚¹ã‚¯2",
                "description": "èª¬æ˜2",
                "dependencies": ["TASK-001"],
                "target_files": ["file2.py"],
                "priority": "medium"
            }
        ]
    }
    
    import json
    (temp_dir / "shared/coordination/tasks.json").write_text(
        json.dumps(tasks, indent=2)
    )
    
    yield temp_dir
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    shutil.rmtree(temp_dir)


def test_get_next_task_returns_independent_task_first(test_project):
    """ä¾å­˜é–¢ä¿‚ã®ãªã„ã‚¿ã‚¹ã‚¯ãŒå…ˆã«è¿”ã•ã‚Œã‚‹"""
    provider = TaskProvider(test_project)
    
    task = provider.get_next_task()
    
    assert task is not None
    assert task.id == "TASK-001"
    assert len(task.dependencies) == 0


def test_get_next_task_respects_dependencies(test_project):
    """ä¾å­˜é–¢ä¿‚ã‚’å°Šé‡ã™ã‚‹"""
    provider = TaskProvider(test_project)
    
    # TASK-001ã‚’å®Œäº†
    provider.mark_completed("TASK-001", ["file1.py"])
    
    # æ¬¡ã¯TASK-002ãŒè¿”ã•ã‚Œã‚‹
    task = provider.get_next_task()
    assert task.id == "TASK-002"


def test_mark_completed_updates_status(test_project):
    """å®Œäº†ãƒãƒ¼ã‚¯ã§ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒæ›´æ–°ã•ã‚Œã‚‹"""
    provider = TaskProvider(test_project)
    
    task = provider.coordinator.get_task("TASK-001")
    assert task.status == TaskStatus.PENDING
    
    provider.mark_completed("TASK-001", ["file1.py"])
    
    assert task.status == TaskStatus.COMPLETED
    assert task.artifacts == ["file1.py"]
    assert task.completed_at is not None


def test_mark_failed_blocks_dependent_tasks(test_project):
    """å¤±æ•—ã™ã‚‹ã¨ä¾å­˜ã‚¿ã‚¹ã‚¯ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹"""
    provider = TaskProvider(test_project)
    
    provider.mark_failed("TASK-001", "ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼")
    
    task2 = provider.coordinator.get_task("TASK-002")
    assert task2.status == TaskStatus.BLOCKED
```

---

## âœ… å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 1.1: TaskProvider
- [ ] `src/cmw/task_provider.py` ã‚’ä½œæˆ
- [ ] `get_next_task()` å®Ÿè£…
- [ ] `get_task_context()` å®Ÿè£…
- [ ] `mark_completed()` å®Ÿè£…
- [ ] `mark_failed()` å®Ÿè£…
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆä½œæˆ
- [ ] å‹•ä½œç¢ºèª

### Phase 1.2: StateManager
- [ ] `src/cmw/state_manager.py` ã‚’ä½œæˆ
- [ ] `acquire_lock()` å®Ÿè£…
- [ ] `release_lock()` å®Ÿè£…
- [ ] `SessionContext` å®Ÿè£…
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆä½œæˆ
- [ ] å‹•ä½œç¢ºèª

### Phase 1.3: ParallelExecutor
- [ ] `src/cmw/parallel_executor.py` ã‚’ä½œæˆ
- [ ] `get_executable_tasks()` å®Ÿè£…
- [ ] `can_run_parallel()` å®Ÿè£…
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆä½œæˆ
- [ ] å‹•ä½œç¢ºèª

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

Phase 1å®Œäº†å¾Œ:
1. GitHubã«ã‚³ãƒŸãƒƒãƒˆ
2. Phase 2.1ï¼ˆClaude Codeçµ±åˆï¼‰ã¸
3. ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ

---

**Phase 1ã‚’å®Œæˆã•ã›ã¦ã€Claude Codeã¨ã®çµ±åˆæº–å‚™ã‚’æ•´ãˆã¾ã—ã‚‡ã†ï¼** ğŸ‰
